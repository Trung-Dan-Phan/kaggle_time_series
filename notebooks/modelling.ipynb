{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: darts in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (0.27.2)\n",
      "Requirement already satisfied: holidays>=0.11.1 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (0.41)\n",
      "Requirement already satisfied: joblib>=0.16.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (3.9.2)\n",
      "Requirement already satisfied: nfoursid>=1.0.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (1.26.1)\n",
      "Requirement already satisfied: pmdarima>=1.8.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (2.0.4)\n",
      "Requirement already satisfied: pyod>=0.9.5 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (1.1.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (1.14.1)\n",
      "Requirement already satisfied: shap>=0.40.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (0.46.0)\n",
      "Requirement already satisfied: statsforecast>=1.4 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (1.7.1)\n",
      "Requirement already satisfied: statsmodels>=0.14.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (0.14.3)\n",
      "Requirement already satisfied: tbats>=1.1.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (1.1.3)\n",
      "Requirement already satisfied: tqdm>=4.60.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (4.12.2)\n",
      "Requirement already satisfied: xarray>=0.17.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (2024.1.1)\n",
      "Requirement already satisfied: xgboost>=1.6.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (2.1.1)\n",
      "Requirement already satisfied: pytorch-lightning<=2.1.2,>=1.5.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (2.1.2)\n",
      "Requirement already satisfied: tensorboardX>=2.1 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (2.6.2.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (2.1.2)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from darts) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from holidays>=0.11.1->darts) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib>=3.3.0->darts) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib>=3.3.0->darts) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib>=3.3.0->darts) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib>=3.3.0->darts) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib>=3.3.0->darts) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib>=3.3.0->darts) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib>=3.3.0->darts) (3.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=1.0.5->darts) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=1.0.5->darts) (2023.3)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from pmdarima>=1.8.0->darts) (3.0.8)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from pmdarima>=1.8.0->darts) (2.2.3)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from pmdarima>=1.8.0->darts) (75.1.0)\n",
      "Requirement already satisfied: numba>=0.51 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from pyod>=0.9.5->darts) (0.60.0)\n",
      "Requirement already satisfied: six in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from pyod>=0.9.5->darts) (1.16.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from pytorch-lightning<=2.1.2,>=1.5.0->darts) (6.0.2)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning<=2.1.2,>=1.5.0->darts) (2024.10.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from pytorch-lightning<=2.1.2,>=1.5.0->darts) (1.3.0.post0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from pytorch-lightning<=2.1.2,>=1.5.0->darts) (0.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.22.0->darts) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.22.0->darts) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.22.0->darts) (2024.8.30)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn>=1.0.1->darts) (3.5.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from shap>=0.40.0->darts) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from shap>=0.40.0->darts) (2.2.1)\n",
      "Requirement already satisfied: fugue>=0.8.1 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from statsforecast>=1.4->darts) (0.8.7)\n",
      "Requirement already satisfied: utilsforecast>=0.0.24 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from statsforecast>=1.4->darts) (0.0.26)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from statsmodels>=0.14.0->darts) (0.5.6)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorboardX>=2.1->darts) (4.25.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch>=1.8.0->darts) (3.12.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch>=1.8.0->darts) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch>=1.8.0->darts) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch>=1.8.0->darts) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from tqdm>=4.60.0->darts) (0.4.6)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning<=2.1.2,>=1.5.0->darts) (3.9.2)\n",
      "Requirement already satisfied: triad>=0.9.3 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from fugue>=0.8.1->statsforecast>=1.4->darts) (0.9.5)\n",
      "Requirement already satisfied: adagio>=0.2.4 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from fugue>=0.8.1->statsforecast>=1.4->darts) (0.2.4)\n",
      "Requirement already satisfied: qpd>=0.4.4 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from fugue>=0.8.1->statsforecast>=1.4->darts) (0.4.4)\n",
      "Requirement already satisfied: fugue-sql-antlr>=0.1.6 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from fugue>=0.8.1->statsforecast>=1.4->darts) (0.2.0)\n",
      "Requirement already satisfied: sqlglot in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from fugue>=0.8.1->statsforecast>=1.4->darts) (20.11.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from numba>=0.51->pyod>=0.9.5->darts) (0.43.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from jinja2->torch>=1.8.0->darts) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from sympy->torch>=1.8.0->darts) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<=2.1.2,>=1.5.0->darts) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<=2.1.2,>=1.5.0->darts) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<=2.1.2,>=1.5.0->darts) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<=2.1.2,>=1.5.0->darts) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<=2.1.2,>=1.5.0->darts) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<=2.1.2,>=1.5.0->darts) (4.0.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime<4.12 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from fugue-sql-antlr>=0.1.6->fugue>=0.8.1->statsforecast>=1.4->darts) (4.11.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from triad>=0.9.3->fugue>=0.8.1->statsforecast>=1.4->darts) (13.0.0)\n",
      "Requirement already satisfied: fs in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from triad>=0.9.3->fugue>=0.8.1->statsforecast>=1.4->darts) (2.4.16)\n",
      "Requirement already satisfied: appdirs~=1.4.3 in c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages (from fs->triad>=0.9.3->fugue>=0.8.1->statsforecast>=1.4->darts) (1.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -lflow (c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lflow (c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lflow (c:\\users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install darts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adana\\anaconda3\\envs\\myenv\\lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 13.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from darts import TimeSeries\n",
    "from darts.models import ARIMA, ExponentialSmoothing, Prophet, NBEATSModel, RNNModel\n",
    "from darts.metrics import mae\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import logging\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "# Suppress cmdstanpy info messages\n",
    "logging.getLogger(\"cmdstanpy\").setLevel(logging.WARNING)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_processed_df = pd.read_csv('../data/final_train_cyclical.csv', index_col=0)\n",
    "test_df = pd.read_csv('../data/final_test_cyclical.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modeling\n",
    "\n",
    "#### Baseline Model\n",
    "- [ ] **Baseline (Naive) Model**: Implement a simple baseline model, such as predicting the last known value or average to set a benchmark for evaluation.\n",
    "\n",
    "#### Model Selection and Training\n",
    "- [ ] **ARIMA / Exponential Smoothing**\n",
    "- [ ] **LSTM/GRU**\n",
    "- [ ] **Other Deep Learning**\n",
    "\n",
    "#### Hyperparameter Tuning\n",
    "- [ ] **Grid/Random Search**: Perform hyperparameter tuning using time-series cross-validation ().\n",
    "\n",
    "#### Model Evaluation\n",
    "- [ ] **Define Evaluation Metrics**: MAE\n",
    "- [ ] **Evaluate on Validation Set**: Assess each model’s performance on the validation set and compare it with the baseline.\n",
    "- [ ] **Residual Analysis**: Plot and analyze residuals to check for patterns or biases.\n",
    "\n",
    "#### Forecasting\n",
    "- [ ] **Make Predictions**: Generate predictions for the future time points provided in `test.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollutants = ['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate using Darts with multiple models\n",
    "models = {\n",
    "    \"ARIMA\": ARIMA(p=1, d=1, q=1),\n",
    "    \"ExponentialSmoothing\": ExponentialSmoothing(),\n",
    "    \"Prophet\": Prophet(),\n",
    "    \"NBEATS\": NBEATSModel(input_chunk_length=30, output_chunk_length=10, n_epochs=10, loss_fn=torch.nn.L1Loss(), random_state=42),\n",
    "    \"LSTM\": RNNModel(model='LSTM', input_chunk_length=30, n_epochs=10, loss_fn=torch.nn.L1Loss(), random_state=42),\n",
    "}\n",
    "def train_and_evaluate_darts(pollutant, models):\n",
    "    series = TimeSeries.from_dataframe(train_processed_df, time_col='id', value_cols=pollutant)\n",
    "    \n",
    "    maes = {model_name: [] for model_name in models.keys()}\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "        \n",
    "    for train_index, test_index in tscv.split(series):\n",
    "        train = series[:len(train_index)]  # Use the last index of train_index\n",
    "        test = series[len(train_index): len(train_index) + len(test_index)]  # The test set starts after train set\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            \n",
    "            # Fit the model\n",
    "            model.fit(train)\n",
    "\n",
    "            # Make predictions\n",
    "            forecast = model.predict(len(test))\n",
    "\n",
    "            # Evaluate the model\n",
    "            score = mae(test, forecast)\n",
    "            maes[model_name].append(score)\n",
    "            \n",
    "    # Calculate average MAE for each model\n",
    "    avg_maes = {model_name: np.mean(scores) for model_name, scores in maes.items()}\n",
    "\n",
    "    return avg_maes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the average MAE across multiple pollutants\n",
    "def compute_avg_mae_for_pollutants(pollutants, models):\n",
    "    overall_maes = {model_name: [] for model_name in list(models.keys())}\n",
    "    \n",
    "    for pollutant in pollutants:\n",
    "        avg_maes = train_and_evaluate_darts(pollutant, models)\n",
    "        \n",
    "        # Add each pollutant's average MAE to the overall list for each model\n",
    "        for model_name, mae_value in avg_maes.items():\n",
    "            overall_maes[model_name].append(mae_value)\n",
    "    \n",
    "    # Calculate the average MAE across all pollutants for each model\n",
    "    final_avg_maes = {model_name: np.mean(scores) for model_name, scores in overall_maes.items()}\n",
    "\n",
    "    return final_avg_maes\n",
    "\n",
    "# Example usage:\n",
    "overall_avg_maes = compute_avg_mae_for_pollutants(pollutants, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final models on full training data and make predictions on test set\n",
    "for pollutant in pollutants:\n",
    "    best_model = NBEATSModel(input_chunk_length=30, output_chunk_length=10, n_epochs=10, loss_fn=torch.nn.L1Loss(), random_state=42)\n",
    "    series = TimeSeries.from_dataframe(train_processed_df, time_col='id', value_cols=pollutant)\n",
    "    \n",
    "    # Fit the model on the training series\n",
    "    best_model.fit(series)\n",
    "    \n",
    "    # Make predictions for the length of the test set\n",
    "    predictions = best_model.predict(len(test_df))\n",
    "    \n",
    "    # Convert predictions to a pandas DataFrame\n",
    "    predictions_df = predictions.pd_dataframe()\n",
    "    \n",
    "    # Assign the predicted values to the corresponding column in test_df\n",
    "    test_df[pollutant] = predictions_df[pollutant].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = test_df[['id', 'valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']]\n",
    "predictions_df['id'] = pd.to_datetime(predictions_df['id'])\n",
    "predictions_df['id'] = predictions_df['id'].dt.strftime('%Y-%m-%d %H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>valeur_NO2</th>\n",
       "      <th>valeur_CO</th>\n",
       "      <th>valeur_O3</th>\n",
       "      <th>valeur_PM10</th>\n",
       "      <th>valeur_PM25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-03 23</td>\n",
       "      <td>27.562361</td>\n",
       "      <td>0.183950</td>\n",
       "      <td>37.864627</td>\n",
       "      <td>8.859465</td>\n",
       "      <td>4.602097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-04 00</td>\n",
       "      <td>26.069686</td>\n",
       "      <td>0.175708</td>\n",
       "      <td>38.507909</td>\n",
       "      <td>8.366501</td>\n",
       "      <td>4.487763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-04 01</td>\n",
       "      <td>25.776206</td>\n",
       "      <td>0.157750</td>\n",
       "      <td>39.418974</td>\n",
       "      <td>8.237877</td>\n",
       "      <td>4.727992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-04 02</td>\n",
       "      <td>32.470129</td>\n",
       "      <td>0.159022</td>\n",
       "      <td>37.578697</td>\n",
       "      <td>8.632615</td>\n",
       "      <td>5.534765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-04 03</td>\n",
       "      <td>39.412055</td>\n",
       "      <td>0.167750</td>\n",
       "      <td>35.631055</td>\n",
       "      <td>9.306403</td>\n",
       "      <td>5.914339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2024-09-24 18</td>\n",
       "      <td>38.941299</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>5.295405</td>\n",
       "      <td>12.661563</td>\n",
       "      <td>8.890298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2024-09-24 19</td>\n",
       "      <td>39.258421</td>\n",
       "      <td>0.122299</td>\n",
       "      <td>4.423819</td>\n",
       "      <td>12.928077</td>\n",
       "      <td>8.710594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2024-09-24 20</td>\n",
       "      <td>38.561565</td>\n",
       "      <td>0.108837</td>\n",
       "      <td>5.037952</td>\n",
       "      <td>12.897201</td>\n",
       "      <td>7.993294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2024-09-24 21</td>\n",
       "      <td>36.624312</td>\n",
       "      <td>0.100032</td>\n",
       "      <td>5.656115</td>\n",
       "      <td>12.817968</td>\n",
       "      <td>7.810771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>2024-09-24 22</td>\n",
       "      <td>35.403078</td>\n",
       "      <td>0.101941</td>\n",
       "      <td>6.529641</td>\n",
       "      <td>13.223607</td>\n",
       "      <td>7.588045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  valeur_NO2  valeur_CO  valeur_O3  valeur_PM10  valeur_PM25\n",
       "0    2024-09-03 23   27.562361   0.183950  37.864627     8.859465     4.602097\n",
       "1    2024-09-04 00   26.069686   0.175708  38.507909     8.366501     4.487763\n",
       "2    2024-09-04 01   25.776206   0.157750  39.418974     8.237877     4.727992\n",
       "3    2024-09-04 02   32.470129   0.159022  37.578697     8.632615     5.534765\n",
       "4    2024-09-04 03   39.412055   0.167750  35.631055     9.306403     5.914339\n",
       "..             ...         ...        ...        ...          ...          ...\n",
       "499  2024-09-24 18   38.941299   0.123977   5.295405    12.661563     8.890298\n",
       "500  2024-09-24 19   39.258421   0.122299   4.423819    12.928077     8.710594\n",
       "501  2024-09-24 20   38.561565   0.108837   5.037952    12.897201     7.993294\n",
       "502  2024-09-24 21   36.624312   0.100032   5.656115    12.817968     7.810771\n",
       "503  2024-09-24 22   35.403078   0.101941   6.529641    13.223607     7.588045\n",
       "\n",
       "[504 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to a DataFrame and save to CSV\n",
    "predictions_df.to_csv('../data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2024-09-03 23\n",
       "1      2024-09-04 00\n",
       "2      2024-09-04 01\n",
       "3      2024-09-04 02\n",
       "4      2024-09-04 03\n",
       "           ...      \n",
       "499    2024-09-24 18\n",
       "500    2024-09-24 19\n",
       "501    2024-09-24 20\n",
       "502    2024-09-24 21\n",
       "503    2024-09-24 22\n",
       "Name: id, Length: 504, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/sample_submission.csv')['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import TimeSeriesSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('final_train_cyclical.csv', index_col='Unnamed: 0', parse_dates=['id'])\n",
    "test_data = pd.read_csv('final_test_cyclical.csv', index_col='Unnamed: 0', parse_dates=['id'])\n",
    "\n",
    "\n",
    "train_data.set_index('id', inplace=True)\n",
    "test_data.set_index('id', inplace=True)\n",
    "\n",
    "# Define target columns\n",
    "target_columns = ['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']\n",
    "\n",
    "# Define feature columns (exclude target variables and 'id')\n",
    "features = [col for col in train_data.columns if col not in target_columns]\n",
    "\n",
    "# Define the target and additional columns for lagging\n",
    "target_columns = ['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']\n",
    "additional_columns = ['tavg', 'wspd', 'wdir']  # Adjust based on relevant features\n",
    "columns_to_lag = target_columns + additional_columns\n",
    "lag_periods = [1, 7, 30]  # Define lag periods\n",
    "\n",
    "# Function to add lagged features\n",
    "def add_lagged_features(data, columns, lags):\n",
    "    for lag in lags:\n",
    "        for col in columns:\n",
    "            data[f\"{col}_lag{lag}\"] = data[col].shift(lag)\n",
    "    return data\n",
    "\n",
    "# Apply lagged features to both training and test datasets\n",
    "train_data = add_lagged_features(train_data, columns_to_lag, lag_periods)\n",
    "\n",
    "train_data.dropna(inplace=True)\n",
    "\n",
    "# Dictionary to store models for each target variable\n",
    "models = {}\n",
    "for target in target_columns:\n",
    "    # Initialize LightGBM model\n",
    "    model = lgb.LGBMRegressor(n_estimators=1000, learning_rate=0.01)\n",
    "\n",
    "    # Fit model on training data\n",
    "    model.fit(train_data[features], train_data[target])\n",
    "\n",
    "    # Store the model\n",
    "    models[target] = model\n",
    "\n",
    "# TimeSeriesSplit for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Evaluate each model using cross-validation\n",
    "mae_scores = {}\n",
    "for target in target_columns:\n",
    "    maes = []\n",
    "    for train_idx, val_idx in tscv.split(train_data):\n",
    "        X_train, X_val = train_data.iloc[train_idx][features], train_data.iloc[val_idx][features]\n",
    "        y_train, y_val = train_data.iloc[train_idx][target], train_data.iloc[val_idx][target]\n",
    "\n",
    "        # Train model\n",
    "        model = lgb.LGBMRegressor(n_estimators=1000, learning_rate=0.01)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on validation set\n",
    "        val_predictions = model.predict(X_val)\n",
    "\n",
    "        # Calculate MAE and store it\n",
    "        maes.append(mean_absolute_error(y_val, val_predictions))\n",
    "\n",
    "    # Store average MAE for each target\n",
    "    mae_scores[target] = np.mean(maes)\n",
    "    print(f\"Average MAE for {target}: {mae_scores[target]}\")\n",
    "\n",
    "# Calculate overall average MAE across all targets\n",
    "average_mae = np.mean(list(mae_scores.values()))\n",
    "print(f\"Overall Average MAE: {average_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store predictions\n",
    "predictions = {}\n",
    "\n",
    "# Make predictions on the test set for each target variable\n",
    "for target in target_columns:\n",
    "    predictions[target] = models[target].predict(test_data[features])\n",
    "\n",
    "# Convert predictions dictionary to a DataFrame\n",
    "predictions_df = pd.DataFrame(predictions, index=test_data.index)\n",
    "predictions_df.index = predictions_df.index.strftime('%Y-%m-%d %H')\n",
    "predictions_df.reset_index(inplace=True)\n",
    "predictions_df.rename(columns={'index': 'id'}, inplace=True)\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to a CSV file for later analysis\n",
    "predictions_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('final_train_cyclical.csv', index_col='Unnamed: 0', parse_dates=['id'])\n",
    "test_data = pd.read_csv('final_test_cyclical.csv', index_col='Unnamed: 0', parse_dates=['id'])\n",
    "\n",
    "train_data.set_index('id', inplace=True)\n",
    "test_data.set_index('id', inplace=True)\n",
    "\n",
    "# Define columns\n",
    "target_columns = ['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']\n",
    "additional_columns = ['tavg', 'wspd', 'wdir']\n",
    "columns_to_lag = target_columns + additional_columns\n",
    "features = [col for col in train_data.columns if col not in target_columns]\n",
    "lag_periods = [1, 7, 30]\n",
    "rolling_windows = [3, 7, 30]\n",
    "\n",
    "# Feature engineering function for lagged and rolling features\n",
    "def add_features(data, columns, lag_periods, rolling_windows):\n",
    "    for lag in lag_periods:\n",
    "        for col in columns:\n",
    "            data[f\"{col}_lag{lag}\"] = data[col].shift(lag)\n",
    "    for window in rolling_windows:\n",
    "        for col in columns:\n",
    "            data[f\"{col}_roll_mean_{window}\"] = data[col].rolling(window).mean()\n",
    "            data[f\"{col}_roll_std_{window}\"] = data[col].rolling(window).std()\n",
    "    return data\n",
    "\n",
    "# Add features to both train and test datasets\n",
    "train_data = add_features(train_data, columns_to_lag, lag_periods, rolling_windows)\n",
    "train_data.dropna(inplace=True)  # Drop NaNs in training data\n",
    "\n",
    "# Hyperparameter tuning with Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 1500),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0)\n",
    "    }\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    maes = []\n",
    "    for train_idx, val_idx in tscv.split(train_data):\n",
    "        X_train, X_val = train_data.iloc[train_idx][features], train_data.iloc[val_idx][features]\n",
    "        y_train, y_val = train_data.iloc[train_idx]['valeur_NO2'], train_data.iloc[val_idx]['valeur_NO2']\n",
    "        model.fit(X_train, y_train)\n",
    "        val_predictions = model.predict(X_val)\n",
    "        maes.append(mean_absolute_error(y_val, val_predictions))\n",
    "    return np.mean(maes)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "best_params = study.best_params\n",
    "\n",
    "# Train LightGBM and CatBoost models for each target with best parameters\n",
    "models, catboost_models = {}, {}\n",
    "for target in target_columns:\n",
    "    lgb_model = lgb.LGBMRegressor(**best_params)\n",
    "    lgb_model.fit(train_data[features], train_data[target])\n",
    "    models[target] = lgb_model\n",
    "\n",
    "    cat_model = CatBoostRegressor(iterations=1000, learning_rate=0.03, depth=6, silent=True)\n",
    "    cat_model.fit(train_data[features], train_data[target])\n",
    "    catboost_models[target] = cat_model\n",
    "\n",
    "# Ensemble predictions by averaging LightGBM and CatBoost\n",
    "def ensemble_predictions(test_data, models, catboost_models):\n",
    "    predictions = {}\n",
    "    for target in target_columns:\n",
    "        lgb_pred = models[target].predict(test_data[features])\n",
    "        cat_pred = catboost_models[target].predict(test_data[features])\n",
    "        predictions[target] = (lgb_pred + cat_pred) / 2\n",
    "    return pd.DataFrame(predictions, index=test_data.index)\n",
    "\n",
    "predictions_df = ensemble_predictions(test_data, models, catboost_models)\n",
    "\n",
    "# Format 'id' column and save to CSV\n",
    "predictions_df.index = predictions_df.index.strftime('%Y-%m-%d %H')\n",
    "predictions_df.reset_index(inplace=True)\n",
    "predictions_df.rename(columns={'index': 'id'}, inplace=True)\n",
    "predictions_df.to_csv(\"predictions_ensemble.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
